{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDjStUVhBmKE"
   },
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# PDF Static Feature Extraction Script\n",
    "# =============================================================\n",
    "# Description:\n",
    "#   This script extracts 40 static structural and content-based\n",
    "#   features from PDF files for malware detection research.\n",
    "# =============================================================\n",
    "\n",
    "import os, re, math, subprocess, time\n",
    "import fitz  # PyMuPDF\n",
    "import PyPDF2\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from pdfminer.high_level import extract_text\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# ========== USER PATHS (EDIT AS NEEDED) ==========\n",
    "# -------------------------------------------------------------\n",
    "input_folder = \"Put your input path here\"\n",
    "output_csv = \"Put your output path here\"\n",
    "error_log = \"A pathway for tracking the corrupted files\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# ========== TEXT EXTRACTION UTILITIES ==========\n",
    "# -------------------------------------------------------------\n",
    "def extract_text_pdfminer(filepath):\n",
    "    \"\"\"Extract visible text from PDF using pdfminer.\"\"\"\n",
    "    try:\n",
    "        return extract_text(filepath)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_pdftotext(filepath):\n",
    "    \"\"\"Extract text using the external pdftotext utility.\"\"\"\n",
    "    try:\n",
    "        output = subprocess.check_output([\"pdftotext\", filepath, \"-\"], stderr=subprocess.DEVNULL)\n",
    "        return output.decode(\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_ocr(filepath, max_pages=1):\n",
    "    \"\"\"OCR fallback for image-based PDFs (first page only).\"\"\"\n",
    "    try:\n",
    "        images = convert_from_path(filepath, dpi=200, first_page=1, last_page=max_pages)\n",
    "        return \"\\n\".join(pytesseract.image_to_string(img) for img in images)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# ========== FEATURE CALCULATION UTILITIES ==========\n",
    "# -------------------------------------------------------------\n",
    "def calculate_entropy(text):\n",
    "    \"\"\"Compute Shannon entropy of text content.\"\"\"\n",
    "    if not text:\n",
    "        return 0\n",
    "    freq = [0] * 256\n",
    "    for char in text:\n",
    "        freq[ord(char) % 256] += 1\n",
    "    freq = [p / len(text) for p in freq if p > 0]\n",
    "    return -sum(p * math.log2(p) for p in freq)\n",
    "\n",
    "def count_name_obfuscations(text):\n",
    "    \"\"\"Count obfuscated names (hex/escaped sequences).\"\"\"\n",
    "    patterns = [\n",
    "        r'/[a-zA-Z]*#\\d{2}', r'/[a-zA-Z]*%[0-9a-fA-F]{2}',\n",
    "        r'/[a-zA-Z]*\\\\x[0-9a-fA-F]{2}', r'/[a-zA-Z]*\\\\[0-7]{1,3}'\n",
    "    ]\n",
    "    return sum(len(re.findall(p, text)) for p in patterns)\n",
    "\n",
    "def log_failure(filepath, message):\n",
    "    \"\"\"Log any failed files for debugging.\"\"\"\n",
    "    with open(error_log, 'a') as logf:\n",
    "        logf.write(f\"{filepath} -- {message}\\n\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# ========== MAIN FEATURE EXTRACTION FUNCTION ==========\n",
    "# -------------------------------------------------------------\n",
    "def extract_pdf_features(filepath):\n",
    "    \"\"\"\n",
    "    Extract 40 static PDF features used for malware analysis.\n",
    "    Returns a dictionary (one row per PDF).\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        \"file_path\": filepath,\n",
    "        \"file_size\": 0, \"title_chars\": 0, \"encrypted\": 0, \"metadata_size\": 0,\n",
    "        \"page_count\": 0, \"valid_pdf_header\": 0, \"image_count\": 0,\n",
    "        \"text_length\": 0, \"object_count\": 0, \"font_object_count\": 0,\n",
    "        \"embedded_file_count\": 0, \"average_embedded_file_size\": 0,\n",
    "        \"stream_count\": 0, \"endstream_count\": 0, \"average_stream_size\": 0,\n",
    "        \"entropy_of_streams\": 0, \"xref_count\": 0, \"xref_entries\": 0,\n",
    "        \"name_obfuscations\": 0, \"total_filters\": 0, \"nested_filter_objects\": 0,\n",
    "        \"objstm_count\": 0, \"js_count\": 0, \"javascript_count\": 0,\n",
    "        \"uri_count\": 0, \"uses_nonstandard_port\": 0, \"action_count\": 0,\n",
    "        \"aa_count\": 0, \"openaction_count\": 0, \"launch_count\": 0,\n",
    "        \"submitform_count\": 0, \"acroform_count\": 0, \"xfa_count\": 0,\n",
    "        \"jbig2decode_count\": 0, \"colors_count\": 0, \"richmedia_count\": 0,\n",
    "        \"trailer_count\": 0, \"startxref_count\": 0,\n",
    "        \"has_multiple_behavioral_keywords_in_one_object\": 0,\n",
    "        \"used_ocr\": 0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        features[\"file_size\"] = os.path.getsize(filepath)\n",
    "    except Exception as e:\n",
    "        log_failure(filepath, f\"Size check failed: {e}\")\n",
    "        return features\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f, strict=False)\n",
    "            features[\"encrypted\"] = int(reader.is_encrypted)\n",
    "            features[\"page_count\"] = len(reader.pages)\n",
    "\n",
    "            # Metadata\n",
    "            meta = reader.metadata\n",
    "            if meta:\n",
    "                features[\"metadata_size\"] = len(str(meta))\n",
    "                title = meta.get('/Title') or os.path.basename(filepath)\n",
    "                features[\"title_chars\"] = len(str(title))\n",
    "\n",
    "            # Validate header\n",
    "            f.seek(0)\n",
    "            header = f.read(1024).decode(errors='ignore')\n",
    "            features[\"valid_pdf_header\"] = int(header.startswith('%PDF'))\n",
    "\n",
    "            # Read content\n",
    "            f.seek(0)\n",
    "            raw = f.read().decode(errors='ignore')\n",
    "\n",
    "            # Stream analysis\n",
    "            features[\"endstream_count\"] = raw.count('endstream')\n",
    "            features[\"stream_count\"] = raw.count('stream')\n",
    "            matches = list(re.finditer(r'stream(.*?)endstream', raw, re.DOTALL))\n",
    "            sizes = [len(m.group(1)) for m in matches if m.group(1)]\n",
    "            entropies = [calculate_entropy(m.group(1)) for m in matches if m.group(1)]\n",
    "            features[\"average_stream_size\"] = sum(sizes) / len(sizes) if sizes else 0\n",
    "            features[\"entropy_of_streams\"] = sum(entropies) / len(entropies) if entropies else 0\n",
    "            features[\"name_obfuscations\"] = count_name_obfuscations(raw)\n",
    "\n",
    "            # Keyword-based detection\n",
    "            keyword_map = {\n",
    "                'objstm_count': '/ObjStm', 'js_count': '/JS', 'javascript_count': '/JavaScript',\n",
    "                'uri_count': '/URI', 'action_count': '/Action', 'aa_count': '/AA',\n",
    "                'openaction_count': '/OpenAction', 'launch_count': '/Launch',\n",
    "                'submitform_count': '/SubmitForm', 'acroform_count': '/AcroForm',\n",
    "                'xfa_count': '/XFA', 'jbig2decode_count': '/JBig2Decode',\n",
    "                'colors_count': '/Colors', 'richmedia_count': '/RichMedia',\n",
    "                'trailer_count': '/Trailer', 'xref_count': '/Xref',\n",
    "                'startxref_count': '/startxref', 'total_filters': '/Filter',\n",
    "                'nested_filter_objects': '/Filter ['\n",
    "            }\n",
    "            for k, v in keyword_map.items():\n",
    "                features[k] = raw.count(v)\n",
    "\n",
    "            if re.search(r'http[s]?://[^:\\s]+:\\d{4,5}', raw):\n",
    "                features[\"uses_nonstandard_port\"] = 1\n",
    "\n",
    "            # Behavioral overlap\n",
    "            objs = re.findall(r'obj(.*?)endobj', raw, re.DOTALL)\n",
    "            behaviors = ['/JS', '/Launch', '/URI', '/OpenAction', '/SubmitForm', '/JavaScript', '/AA']\n",
    "            for block in objs:\n",
    "                if sum(1 for b in behaviors if b in block) >= 2:\n",
    "                    features[\"has_multiple_behavioral_keywords_in_one_object\"] += 1\n",
    "\n",
    "        # Structure and text via PyMuPDF\n",
    "        try:\n",
    "            doc = fitz.open(filepath)\n",
    "            font_names = set()\n",
    "            for page in doc:\n",
    "                features[\"image_count\"] += len(page.get_images(full=True))\n",
    "                font_names.update([f[3] for f in page.get_fonts() if f[3]])\n",
    "            features[\"font_object_count\"] = len(font_names)\n",
    "            features[\"object_count\"] = doc.xref_length()\n",
    "            features[\"xref_entries\"] = sum(1 for i in range(doc.xref_length()) if doc.xref_object(i, compressed=False))\n",
    "            features[\"text_length\"] = sum(len(page.get_text()) for page in doc)\n",
    "        except Exception:\n",
    "            text = extract_text_pdfminer(filepath) or extract_text_pdftotext(filepath)\n",
    "            if not text.strip():\n",
    "                text = extract_text_ocr(filepath)\n",
    "                features[\"used_ocr\"] = 1\n",
    "            features[\"text_length\"] = len(text)\n",
    "\n",
    "    except Exception as e:\n",
    "        log_failure(filepath, f\"Extraction failed: {e}\")\n",
    "        print(f\"âŒ Failed: {filepath} â€” {e}\")\n",
    "\n",
    "    return features\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# ========== EXECUTION LOOP ==========\n",
    "# -------------------------------------------------------------\n",
    "processed = set()\n",
    "if os.path.exists(output_csv):\n",
    "    try:\n",
    "        existing_df = pd.read_csv(output_csv, usecols=[\"file_path\"])\n",
    "        processed = set(existing_df[\"file_path\"].tolist())\n",
    "        print(f\"ðŸ” Resuming previous run. {len(processed)} files already processed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not read existing CSV: {e}\")\n",
    "\n",
    "first_write = not os.path.exists(output_csv)\n",
    "\n",
    "with open(output_csv, 'a', encoding='utf-8', newline='') as f:\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if fname.lower().endswith('.pdf'):\n",
    "            path = os.path.join(input_folder, fname)\n",
    "            if path in processed:\n",
    "                continue\n",
    "\n",
    "            print(f\"ðŸ“„ Processing: {fname}\")\n",
    "            start = time.time()\n",
    "            feats = extract_pdf_features(path)\n",
    "\n",
    "            pd.DataFrame([feats]).to_csv(f, index=False, header=first_write)\n",
    "            first_write = False\n",
    "            print(f\"âœ… Done in {round(time.time() - start, 2)} sec\")\n",
    "\n",
    "print(\"ðŸŽ‰ All files processed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPCzkrD0K9ShWKWB3T2akXE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
